{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Implementing simple Chatbot Using LangGraph",
   "id": "1ff82854c9dc52e4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-17T09:47:24.088294Z",
     "start_time": "2025-11-17T09:47:23.211452Z"
    }
   },
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Reducers\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/binod.kafle/Documents/personal/learning/agentic_ai/.venv/lib/python3.14/site-packages/langchain_core/_api/deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T09:51:57.597552Z",
     "start_time": "2025-11-17T09:51:57.576167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ],
   "id": "3dab28dd121cb5a9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b64105f79204ed48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T09:54:59.782126Z",
     "start_time": "2025-11-17T09:54:59.760855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ],
   "id": "4ff9b9eb6a84d1d3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T09:56:43.120289Z",
     "start_time": "2025-11-17T09:56:37.262732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm.invoke()"
   ],
   "id": "42b40fb00d7809e",
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRateLimitError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_openai\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChatOpenAI\n\u001B[32m      2\u001B[39m llm = ChatOpenAI(model=\u001B[33m\"\u001B[39m\u001B[33mgpt-4o\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[43mllm\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mHello\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/agentic_ai/.venv/lib/python3.14/site-packages/langchain_core/language_models/chat_models.py:385\u001B[39m, in \u001B[36mBaseChatModel.invoke\u001B[39m\u001B[34m(self, input, config, stop, **kwargs)\u001B[39m\n\u001B[32m    371\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    372\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m    373\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    378\u001B[39m     **kwargs: Any,\n\u001B[32m    379\u001B[39m ) -> AIMessage:\n\u001B[32m    380\u001B[39m     config = ensure_config(config)\n\u001B[32m    381\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[32m    382\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mAIMessage\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    383\u001B[39m         cast(\n\u001B[32m    384\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mChatGeneration\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m--> \u001B[39m\u001B[32m385\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    386\u001B[39m \u001B[43m                \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    387\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    388\u001B[39m \u001B[43m                \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcallbacks\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    389\u001B[39m \u001B[43m                \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtags\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    390\u001B[39m \u001B[43m                \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    391\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_name\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    392\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    393\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    394\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m.generations[\u001B[32m0\u001B[39m][\u001B[32m0\u001B[39m],\n\u001B[32m    395\u001B[39m         ).message,\n\u001B[32m    396\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/agentic_ai/.venv/lib/python3.14/site-packages/langchain_core/language_models/chat_models.py:1104\u001B[39m, in \u001B[36mBaseChatModel.generate_prompt\u001B[39m\u001B[34m(self, prompts, stop, callbacks, **kwargs)\u001B[39m\n\u001B[32m   1095\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   1096\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgenerate_prompt\u001B[39m(\n\u001B[32m   1097\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1101\u001B[39m     **kwargs: Any,\n\u001B[32m   1102\u001B[39m ) -> LLMResult:\n\u001B[32m   1103\u001B[39m     prompt_messages = [p.to_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[32m-> \u001B[39m\u001B[32m1104\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/agentic_ai/.venv/lib/python3.14/site-packages/langchain_core/language_models/chat_models.py:914\u001B[39m, in \u001B[36mBaseChatModel.generate\u001B[39m\u001B[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[39m\n\u001B[32m    911\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(input_messages):\n\u001B[32m    912\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    913\u001B[39m         results.append(\n\u001B[32m--> \u001B[39m\u001B[32m914\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    915\u001B[39m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    916\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    917\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    918\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    919\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    920\u001B[39m         )\n\u001B[32m    921\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    922\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/agentic_ai/.venv/lib/python3.14/site-packages/langchain_core/language_models/chat_models.py:1208\u001B[39m, in \u001B[36mBaseChatModel._generate_with_cache\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1206\u001B[39m     result = generate_from_stream(\u001B[38;5;28miter\u001B[39m(chunks))\n\u001B[32m   1207\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m inspect.signature(\u001B[38;5;28mself\u001B[39m._generate).parameters.get(\u001B[33m\"\u001B[39m\u001B[33mrun_manager\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1208\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1209\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1210\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1211\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1212\u001B[39m     result = \u001B[38;5;28mself\u001B[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/agentic_ai/.venv/lib/python3.14/site-packages/langchain_openai/chat_models/base.py:1333\u001B[39m, in \u001B[36mBaseChatOpenAI._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1331\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m raw_response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(raw_response, \u001B[33m\"\u001B[39m\u001B[33mhttp_response\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m   1332\u001B[39m         e.response = raw_response.http_response  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1333\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m   1334\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   1335\u001B[39m     \u001B[38;5;28mself\u001B[39m.include_response_headers\n\u001B[32m   1336\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m raw_response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1337\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(raw_response, \u001B[33m\"\u001B[39m\u001B[33mheaders\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1338\u001B[39m ):\n\u001B[32m   1339\u001B[39m     generation_info = {\u001B[33m\"\u001B[39m\u001B[33mheaders\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mdict\u001B[39m(raw_response.headers)}\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/agentic_ai/.venv/lib/python3.14/site-packages/langchain_openai/chat_models/base.py:1328\u001B[39m, in \u001B[36mBaseChatOpenAI._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1321\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m _construct_lc_result_from_responses_api(\n\u001B[32m   1322\u001B[39m             response,\n\u001B[32m   1323\u001B[39m             schema=original_schema_obj,\n\u001B[32m   1324\u001B[39m             metadata=generation_info,\n\u001B[32m   1325\u001B[39m             output_version=\u001B[38;5;28mself\u001B[39m.output_version,\n\u001B[32m   1326\u001B[39m         )\n\u001B[32m   1327\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1328\u001B[39m         raw_response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwith_raw_response\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mpayload\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1329\u001B[39m         response = raw_response.parse()\n\u001B[32m   1330\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/agentic_ai/.venv/lib/python3.14/site-packages/openai/_legacy_response.py:364\u001B[39m, in \u001B[36mto_raw_response_wrapper.<locals>.wrapped\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    360\u001B[39m extra_headers[RAW_RESPONSE_HEADER] = \u001B[33m\"\u001B[39m\u001B[33mtrue\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    362\u001B[39m kwargs[\u001B[33m\"\u001B[39m\u001B[33mextra_headers\u001B[39m\u001B[33m\"\u001B[39m] = extra_headers\n\u001B[32m--> \u001B[39m\u001B[32m364\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m cast(LegacyAPIResponse[R], \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/agentic_ai/.venv/lib/python3.14/site-packages/openai/_utils/_utils.py:286\u001B[39m, in \u001B[36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    284\u001B[39m             msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[32m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    285\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[32m--> \u001B[39m\u001B[32m286\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/agentic_ai/.venv/lib/python3.14/site-packages/openai/resources/chat/completions/completions.py:1189\u001B[39m, in \u001B[36mCompletions.create\u001B[39m\u001B[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m   1142\u001B[39m \u001B[38;5;129m@required_args\u001B[39m([\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m], [\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m   1143\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate\u001B[39m(\n\u001B[32m   1144\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1186\u001B[39m     timeout: \u001B[38;5;28mfloat\u001B[39m | httpx.Timeout | \u001B[38;5;28;01mNone\u001B[39;00m | NotGiven = not_given,\n\u001B[32m   1187\u001B[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001B[32m   1188\u001B[39m     validate_response_format(response_format)\n\u001B[32m-> \u001B[39m\u001B[32m1189\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1190\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m/chat/completions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1191\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1192\u001B[39m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m   1193\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessages\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1194\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodel\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1195\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43maudio\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1196\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfrequency_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1197\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunction_call\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1198\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunctions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1199\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogit_bias\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1200\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1201\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_completion_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_completion_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1202\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1203\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1204\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodalities\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodalities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1205\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mn\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1206\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mparallel_tool_calls\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1207\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprediction\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1208\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpresence_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1209\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprompt_cache_key\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt_cache_key\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1210\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprompt_cache_retention\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt_cache_retention\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1211\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mreasoning_effort\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_effort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1212\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mresponse_format\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1213\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msafety_identifier\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43msafety_identifier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1214\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mseed\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1215\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mservice_tier\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1216\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstop\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1217\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstore\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1218\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1219\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1220\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtemperature\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1221\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtool_choice\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1222\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtools\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1223\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_logprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1224\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_p\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1225\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43muser\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1226\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mverbosity\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbosity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1227\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mweb_search_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mweb_search_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1228\u001B[39m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1229\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCompletionCreateParamsStreaming\u001B[49m\n\u001B[32m   1230\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\n\u001B[32m   1231\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCompletionCreateParamsNonStreaming\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1232\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1233\u001B[39m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1234\u001B[39m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[32m   1235\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1236\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1237\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1238\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1239\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/agentic_ai/.venv/lib/python3.14/site-packages/openai/_base_client.py:1259\u001B[39m, in \u001B[36mSyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[39m\n\u001B[32m   1245\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1246\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1247\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1254\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1255\u001B[39m ) -> ResponseT | _StreamT:\n\u001B[32m   1256\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1257\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001B[32m   1258\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1259\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/personal/learning/agentic_ai/.venv/lib/python3.14/site-packages/openai/_base_client.py:1047\u001B[39m, in \u001B[36mSyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1044\u001B[39m             err.response.read()\n\u001B[32m   1046\u001B[39m         log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1047\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1049\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1051\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mcould not resolve response (should never happen)\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mRateLimitError\u001B[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T09:58:29.922466Z",
     "start_time": "2025-11-17T09:58:29.182571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm_groq = ChatGroq(model=\"groq/compound\")\n",
    "llm_groq.invoke(\"Hey I am Binod and I like to play cricket\")"
   ],
   "id": "6a04c0934f0fc9b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hey Binod! Nice to meet you. Cricketâ€™s a great gameâ€”whatâ€™s your favorite format or team?', additional_kwargs={'reasoning_content': '<Think>\\n\\n</Think>'}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 252, 'total_tokens': 340, 'completion_time': 0.186211, 'prompt_time': 0.047556, 'queue_time': 0.134011, 'total_time': 0.233767}, 'model_name': 'groq/compound', 'system_fingerprint': None, 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--fdeec55f-485f-4969-ae2d-5ff0a03b01ce-0', usage_metadata={'input_tokens': 252, 'output_tokens': 88, 'total_tokens': 340})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### We will start with creating Nodes",
   "id": "e62ad7dda750b6f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T10:06:34.583635Z",
     "start_time": "2025-11-17T10:06:34.578005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def superbot(state:State):\n",
    "    return {\"messages\":[llm_groq.invoke(state['messages'])]}"
   ],
   "id": "6480deaacf3e5768",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T10:06:39.556465Z",
     "start_time": "2025-11-17T10:06:39.471927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "graph = StateGraph(State)\n",
    "\n",
    "graph.add_node(\"SuperBot\", superbot)\n",
    "\n",
    "graph.add_edge(START, \"SuperBot\")\n",
    "graph.add_edge(\"SuperBot\", END)\n",
    "\n",
    "graph_builder = graph.compile()\n",
    "# view\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph_builder.get_graph().draw_mermaid_png()))"
   ],
   "id": "ed14a6fd2fb60fcf",
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T10:06:41.933405Z",
     "start_time": "2025-11-17T10:06:41.569259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Invocation\n",
    "graph_builder.invoke({\"messages\": \"Hi my name is Binod and I like cricket\"})"
   ],
   "id": "c5094f96807f640c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi my name is Binod and I like cricket', additional_kwargs={}, response_metadata={}, id='6c7aebc3-eabf-4df4-9d6c-510559c4ab84'),\n",
       "  AIMessage(content='Hi Binod! Nice to meet you. ðŸ˜Š  \\nCricketâ€™s a great sportâ€”do you have a favorite team or player?', additional_kwargs={'reasoning_content': '<Think>\\n\\n</Think>'}, response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 250, 'total_tokens': 325, 'completion_time': 0.157187, 'prompt_time': 0.007838, 'queue_time': 0.102587, 'total_time': 0.165024}, 'model_name': 'groq/compound', 'system_fingerprint': None, 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--2d740474-0f42-4236-8403-2dfd92477fb5-0', usage_metadata={'input_tokens': 250, 'output_tokens': 75, 'total_tokens': 325})]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Streaming the responses",
   "id": "a7ca5a3096663852"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T10:10:14.617147Z",
     "start_time": "2025-11-17T10:10:14.137983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for event in graph_builder.stream({\"messages\":\"Hello My name is Binod\"}, stream_mode=\"updates\"):\n",
    "    print(event)"
   ],
   "id": "c354b40ce78a6310",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SuperBot': {'messages': [AIMessage(content='Hello, Binod! Nice to meet you. How can I help you today?', additional_kwargs={'reasoning_content': '<Think>\\n\\n</Think>'}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 242, 'total_tokens': 311, 'completion_time': 0.147075, 'prompt_time': 0.008794, 'queue_time': 0.139744, 'total_time': 0.155869}, 'model_name': 'groq/compound', 'system_fingerprint': None, 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--89d340b4-1de4-4442-b6a0-c2a67253a774-0', usage_metadata={'input_tokens': 242, 'output_tokens': 69, 'total_tokens': 311})]}}\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "77b0a72d181d8503"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
